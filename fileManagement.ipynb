{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benmoussa-marouane/data-science/blob/master/fileManagement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGVb9eII3Lc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# access data in drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#cd to unet directory\n",
        "%cd drive/My\\ Drive/\\Air-D/\\Unet-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E85kNsTiDWN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Imports\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import os,errno\n",
        "import glob\n",
        "import pathlib\n",
        "import shutil\n",
        "import numpy as np\n",
        "import copy\n",
        "from collections import Counter\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import jaccard_score\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#local library\n",
        "# import manageFiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rCSP-dbMw88x"
      },
      "source": [
        "# Image segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MQmKthrSBCld",
        "colab": {}
      },
      "source": [
        "# Install required libs\n",
        "!pip  install git+https://github.com/qubvel/segmentation_models\n",
        "# ! pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g87--n2AtyO_",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oWe0_rQM4JbC"
      },
      "source": [
        "#### Dataset of pollution "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2glvAQmDHAA",
        "colab_type": "text"
      },
      "source": [
        "Run this only once, it orginize your data using the local library manageFiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5VH7OMnW5I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask = tf.cast(input_mask, tf.float32) / 255.0\n",
        "  return input_image, input_mask\n",
        "\n",
        "@tf.function\n",
        "def FlipImages(input_image, input_mask):\n",
        "  \n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJE30imIFF43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def CreateTraining(Quartier, new_path ,dstP):\n",
        "\n",
        "# # Training Ids\n",
        "#     for i in Quartier :\n",
        "#         ids = next(os.walk(os.path.join(dstP, str(i))))[1]\n",
        "#         # print(ids)\n",
        "#         for j in ids:\n",
        "#           src = os.path.join(dstP, str(i) ,str(j))\n",
        "#           dst = os.path.join(new_path, \"test\")\n",
        "\n",
        "# # move data to their correspondant quartier\n",
        "#           shutil.move(src, dst)\n",
        "\n",
        "# path_principale = \"/content/drive/My Drive/Air-D/Unet-5/new_dataset_images\"\n",
        "# TrainP = os.path.join(path_principale,\"Train\")\n",
        "# TestP = os.path.join(path_principale,\"Test\")\n",
        "\n",
        "# new_path = \"/content/drive/My Drive/Air-D/Unet-5/dataset_images\"\n",
        "\n",
        "# quartier_id  = next(os.walk(TestP))[1]\n",
        "\n",
        "# # print(quartier_id)\n",
        "# CreateTraining(quartier_id, new_path, TestP )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhLDqR-EEUWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set some parameters\n",
        "im_width = 128\n",
        "im_height = 128\n",
        "border = 5\n",
        "path_train = '../input/train/'\n",
        "path_test = '../input/test/'\n",
        "\n",
        "path_principale = \"/content/drive/My Drive/Air-D/Unet-5/new_dataset_images\"\n",
        "TrainP = os.path.join(path_principale,\"Train\")\n",
        "TestP = os.path.join(path_principale,\"Test\")\n",
        "\n",
        "\n",
        "# Load The Images\n",
        "# Get and resize train images and masks\n",
        "\n",
        "def get_data(path, train=True):\n",
        "\n",
        "    ids = next(os.walk(path + \"images\"))[2]\n",
        "    X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
        "\n",
        "    if train:\n",
        "        y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
        "    print('Getting and resizing images ... ')\n",
        "\n",
        "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
        "        # Load images\n",
        "        img = load_img(path + '/images/' + id_, grayscale=True)\n",
        "        x_img = img_to_array(img)\n",
        "        x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "\n",
        "        # Load masks\n",
        "        if train:\n",
        "            mask = img_to_array(load_img(path + '/masks/' + id_, grayscale=True))\n",
        "            mask = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "\n",
        "        # Save images\n",
        "        X[n, ..., 0] = x_img.squeeze() / 255\n",
        "        if train:\n",
        "            y[n] = mask / 255\n",
        "    print('Done!')\n",
        "    if train:\n",
        "        return X, y\n",
        "    else:\n",
        "        return X\n",
        "    \n",
        "X, y = get_data(path_train, train=True)\n",
        "\n",
        "# Getting and resizing images \n",
        "\n",
        "# Split train and valid\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=2018)\n",
        "\n",
        "# Check if training data looks all right\n",
        "ix = random.randint(0, len(X_train))\n",
        "has_mask = y_train[ix].max() > 0\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "ax[0].imshow(X_train[ix, ..., 0], cmap='seismic', interpolation='bilinear')\n",
        "if has_mask:\n",
        "    ax[0].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\n",
        "ax[0].set_title('Seismic')\n",
        "\n",
        "ax[1].imshow(y_train[ix].squeeze(), interpolation='bilinear', cmap='gray')\n",
        "ax[1].set_title('Salt');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwwduR_pJ3uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #########################################################################################################################################\n",
        "# #                                                       Generator                                                                       #\n",
        "# #########################################################################################################################################\n",
        "\n",
        "# class DataGen(keras.utils.Sequence):\n",
        "\n",
        "#     def __init__(self, quartier_ids, path, image_size=128,shuffle=True):\n",
        "#         self.quartier_ids = quartier_ids\n",
        "#         self.ids = []\n",
        "#         self.path = path\n",
        "#         self.image_size = image_size\n",
        "#         self.shuffle = shuffle\n",
        "#         self.on_epoch_end()\n",
        "\n",
        "#     def __load__(self):\n",
        "#         images_x  = []\n",
        "#         images_y = []\n",
        "    \n",
        "#         ## Path\n",
        "#         for Q in self.quartier_ids:\n",
        "#             Q_path = os.path.join(self.path, Q)\n",
        "#             self.ids = os.listdir(Q_path)\n",
        "\n",
        "#             for id_name in self.ids :\n",
        "#                 y_path = os.path.join(Q_path,id_name,\"Y\",\"pollutionMap\") + \".png\"\n",
        "                \n",
        "#                 ## Reading Image y\n",
        "#                 image_y = cv2.imread(y_path,cv2.IMREAD_GRAYSCALE)\n",
        "#                 image_y = cv2.resize(image_y,(self.image_size,self.image_size))\n",
        "                \n",
        "#                 ## Normalazing\n",
        "#                 image_y = image_y/255.0        \n",
        "#                 image_y = np.reshape(image_y,(self.image_size,self.image_size,1))\n",
        "#                 ## Reading X images \n",
        "                \n",
        "#                 x_path = os.path.join(Q_path,id_name,\"X/\")\n",
        "#                 all_x_files_names = sorted(os.listdir(x_path))\n",
        "\n",
        "#                 image_group_x=np.zeros((128,128,len(all_x_files_names)))\n",
        "                \n",
        "#                 for i,file_name in enumerate(all_x_files_names):\n",
        "\n",
        "#                     path_x_file_name = os.path.join(x_path,file_name)\n",
        "#                     image_x = cv2.imread(path_x_file_name,cv2.IMREAD_GRAYSCALE)\n",
        "#                     image_x = cv2.resize(image_x,(128, 128))\n",
        "#                     ## Normlazing\n",
        "#                     image_x=image_x/255.0\n",
        "#                     image_group_x[:,:,i]=image_x\n",
        "#                     # save images  \n",
        "#                     images_x.append(image_group_x)\n",
        "#                     images_y.append(image_y)\n",
        "\n",
        "#                     print(\" quartier {0} Id name {1}\".format(Q,file_name))    \n",
        "        \n",
        "#         images_x  = np.array(images_x)    \n",
        "#         images_y = np.array(images_y)\n",
        "\n",
        "#         print(\" \")\n",
        "#         print(\"images of training \",len(images_x))\n",
        "#         print(\" \")\n",
        "#         print(\"images y \", len(images_y))\n",
        "\n",
        "#         return images_x, images_y\n",
        "    \n",
        "#     def on_epoch_end(self):\n",
        "#         \"\"\"'Updates indexes after each epoch'\"\"\"\n",
        "#         self.indexes = np.arange(len(self.ids))\n",
        "#         if self.shuffle == True:\n",
        "#               np.random.shuffle(self.indexes)\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return int(np.ceil(len(self.ids)/float(self.batch_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcCCk8djrY3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Getting testing\n",
        "# Test_ids = os.listdir(TestP) \n",
        "# gen_test = DataGen(Test_ids, TestP, image_size=128)\n",
        "# x_test,y_test = gen_test.__load__()\n",
        "# print(x_test.shape , y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3RNjzp8cL4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_size = 256\n",
        "# epochs = 3\n",
        "# batch_size = 6\n",
        "# val_data_size = 12\n",
        "\n",
        "# ## Training Ids\n",
        "\n",
        "# Train_ids = os.listdir(TrainP)\n",
        "\n",
        "# ## validation Ids \n",
        "# Test_ids = os.listdir(TestP) \n",
        "\n",
        "# #Getting Training\n",
        "# gen = DataGen(Train_ids, TrainP, image_size=128)\n",
        "# x,y = gen.__load__()\n",
        "# print(x.shape , y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmFg78W_nHqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#########################################################################################################################################\n",
        "\n",
        "class DataGen(keras.utils.Sequence):\n",
        "    def __init__(self, ids, path, batch_size=8, image_size=128,shuffle=True):\n",
        "        self.ids = ids\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __load__(self, id_name):\n",
        "        \n",
        "        ## Path\n",
        "        y_path = os.path.join(self.path, id_name,\"Y\",\"pollutionMap\") + \".png\"\n",
        "        x_path = os.path.join(self.path, id_name,\"X/\")\n",
        "        all_x_files_names = sorted(os.listdir(x_path))\n",
        "        ## Reading Image\n",
        "        image_group_x=np.zeros((self.image_size,self.image_size,len(all_x_files_names)))\n",
        "\n",
        "        ## Reading Image\n",
        "        for i,file_name in enumerate(all_x_files_names):\n",
        "            \n",
        "            path_x_file_name=os.path.join(x_path,file_name)\n",
        "            image_x= cv2.imread(path_x_file_name,cv2.IMREAD_GRAYSCALE)\n",
        "            image_x= cv2.resize(image_x,(self.image_size, self.image_size))\n",
        "            ## Normalazing\n",
        "            image_x=image_x/255.0\n",
        "            image_group_x[:,:,i]=image_x\n",
        "        \n",
        "        \n",
        "        ## Reading Image\n",
        "        image_y=cv2.imread(y_path,cv2.IMREAD_GRAYSCALE)\n",
        "        image_y=cv2.resize(image_y,(self.image_size,self.image_size))\n",
        "        ## Normalazing\n",
        "        image_y = image_y/255.0\n",
        "        \n",
        "        image_y=np.reshape(image_y,(self.image_size,self.image_size,1))\n",
        "        \n",
        "        print(\"image_x_group\",np.shape(image_group_x))\n",
        "        print(\"image_x\",np.shape(image_x))\n",
        "        print(\"image_y\",np.shape(image_y))\n",
        "        \n",
        "        return image_group_x,image_y\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        if(index+1)*self.batch_size > len(self.ids):\n",
        "            self.batch_size = len(self.ids) - index*self.batch_size\n",
        "        \n",
        "        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
        "        \n",
        "        images_x  = []\n",
        "        image_y = []\n",
        "        \n",
        "        for id_name in files_batch:\n",
        "            _imgs_x, _img_y = self.__load__(id_name)\n",
        "            images_x.append(_imgs_x)\n",
        "            image_y.append(_img_y)\n",
        "            \n",
        "        images_x  = np.array(images_x)    \n",
        "        image_y = np.array(image_y)\n",
        "        \n",
        "        return images_x, image_y\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "          'Updates indexes after each epoch'\n",
        "          self.indexes = np.arange(len(self.ids))\n",
        "          if self.shuffle == True:\n",
        "              np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.ids)/float(self.batch_size)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FScEELRnH3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################################################################################################################################\n",
        "\n",
        "#########################################################################################################################################\n",
        "\n",
        "image_size = 128\n",
        "train_path = \"dataset_images/train\"\n",
        "test_path = \"dataset_images/test\"\n",
        "epochs = 100\n",
        "batch_size = 6\n",
        "## Validation Data Size\n",
        "val_data_size = 12\n",
        "\n",
        "#########################################################################################################################################\n",
        "\n",
        "#########################################################################################################################################\n",
        "\n",
        "## Training Ids\n",
        "\n",
        "train_ids = next(os.walk(train_path))[1]\n",
        "test_ids = next(os.walk(test_path))[1]\n",
        "print(train_ids[0])\n",
        "\n",
        "valid_ids = train_ids[:val_data_size]\n",
        "train_ids = train_ids[val_data_size:]\n",
        "\n",
        "gen = DataGen(train_ids, train_path, batch_size=batch_size, image_size=image_size)\n",
        "\n",
        "x, y = gen.__getitem__(1)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "r = random.randint(0, len(x)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YbU7tw3d2S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "# save TRAINING data as hdf5 \n",
        "with h5py.File(os.path.join( '/content/drive/My Drive/Air-D/Unet-5/dataset_images' , 'Training.hdf5') , 'w') as f:\n",
        "    f.create_dataset('Training_X_3808', data=x)\n",
        "    f.create_dataset('Training_Y_3808', data=y)\n",
        "    \n",
        "# save Testing data as HDF5\n",
        "with h5py.File(os.path.join( '/content/drive/My Drive/Air-D/Unet-5/dataset_images', 'Testing.hdf5') , 'w') as f:\n",
        "    f.create_dataset('Testing_X_', data=x_test)\n",
        "    f.create_dataset('Testing_Y_', data=y_test)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgE-E-cSXLgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.shape , y.shape)\n",
        "print(x_test.shape , y_test.shape)\n",
        "# r = random.randint(0, len(x)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "65-qHTjX5VZh"
      },
      "source": [
        "The dataset already contains the required splits of test and train and so let's continue to use the same split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yHwj2-8SaQli",
        "colab": {}
      },
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "39fYScNz9lmo",
        "colab": {}
      },
      "source": [
        "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test = dataset['test'].map(load_image_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DeFwFDN6EVoI",
        "colab": {}
      },
      "source": [
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xa3gMAE_9qNa"
      },
      "source": [
        "Let's take a look at an image example and it's correponding mask from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3N2RPAAW9q4W",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a6u_Rblkteqb",
        "colab": {}
      },
      "source": [
        "for image, mask in train.take(1):\n",
        "  sample_image, sample_mask = image, mask\n",
        "display([sample_image, sample_mask])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FAOe93FRMk3w"
      },
      "source": [
        "## Define the model\n",
        "The model being used here is a modified U-Net. A U-Net consists of an encoder (downsampler) and decoder (upsampler). In-order to learn robust features, and reduce the number of trainable parameters, a pretrained model can be used as the encoder. Thus, the encoder for this task will be a pretrained MobileNetV2 model, whose intermediate outputs will be used, and the decoder will be the upsample block already implemented in TensorFlow Examples in the [Pix2pix tutorial](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py). \n",
        "\n",
        "The reason to output three channels is because there are three possible labels for each pixel. Think of this as multi-classification where each pixel is being classified into three classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c6iB4iMvMkX9",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W4mQle3lthit"
      },
      "source": [
        "As mentioned, the encoder will be a pretrained MobileNetV2 model which is prepared and ready to use in [tf.keras.applications](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications). The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "liCeLH0ctjq7",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
        "\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KPw8Lzra5_T9"
      },
      "source": [
        "The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p0ZbfywEbZpJ",
        "colab": {}
      },
      "source": [
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "45HByxpVtrPF",
        "colab": {}
      },
      "source": [
        "def unet_model(output_channels):\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same', activation='softmax')  #64x64 -> 128x128\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0DGH_4T0VYn"
      },
      "source": [
        "## Train the model\n",
        "Now, all that is left to do is to compile and train the model. The loss being used here is losses.sparse_categorical_crossentropy. The reason to use this loss function is because the network is trying to assign each pixel a label, just like multi-class prediction. In the true segmentation mask, each pixel has either a {0,1,2}. The network here is outputting three channels. Essentially, each channel is trying to learn to predict a class, and losses.sparse_categorical_crossentropy is the recommended loss for such a scenario. Using the output of the network, the label assigned to the pixel is the channel with the highest value. This is what the create_mask function is doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6he36HK5uKAc",
        "colab": {}
      },
      "source": [
        "model = unet_model(OUTPUT_CHANNELS)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xVMzbIZLcyEF"
      },
      "source": [
        "Have a quick look at the resulting model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sw82qF1Gcovr",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tc3MiEO2twLS"
      },
      "source": [
        "Let's try out the model to see what it predicts before training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UwvIKLZPtxV_",
        "colab": {}
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLNsrynNtx4d",
        "colab": {}
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X_1CC0T4dho3",
        "colab": {}
      },
      "source": [
        "show_predictions()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22AyVYWQdkgk"
      },
      "source": [
        "Let's observe how the model improves while it is training. To accomplish this task, a callback function is defined below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHrHsqijdmL6",
        "colab": {}
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "StKDH_B9t4SD",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_mu0SAbt40Q",
        "colab": {}
      },
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "unP3cnxo_N72"
      },
      "source": [
        "## Make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7BVXldSo-0mW"
      },
      "source": [
        "Let's make some predictions. In the interest of saving time, the number of epochs was kept small, but you may set this higher to achieve more accurate results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ikrzoG24qwf5",
        "colab": {}
      },
      "source": [
        "show_predictions(test_dataset, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R24tahEqmSCk"
      },
      "source": [
        "## Next steps\n",
        "Now that you have an understanding of what image segmentation is and how it works, you can try this tutorial out with different intermediate layer outputs, or even different pretrained model. You may also challenge yourself by trying out the [Carvana](https://www.kaggle.com/c/carvana-image-masking-challenge/overview) image masking challenge hosted on Kaggle.\n",
        "\n",
        "You may also want to see the [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) for another model you can retrain on your own data."
      ]
    }
  ]
}